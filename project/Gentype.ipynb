{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HLA-A allele clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gentype import EnsemblClient, DataManager, PiCollapsedNonparametricGibbsSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Database_Name = \"Gentype_DB.db\"\n",
    "client = EnsemblClient()\n",
    "data_manager = DataManager(client, Database_Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize storable data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetched = False\n",
    "inference_matrix = None\n",
    "models = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore stored data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%store -d fetched # if you want to refetch the data, uncomment this line\n",
    "#%store -d inference_matrix # if you want to recompute the inference_matrix, uncomment this line\n",
    "#%store -d models # if you want to recompute the models, uncomment this line\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Collecting and preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetches all HLA-A data obtained in 1000 Genomes project phase3 and stores them in a local sqlite server. This only needs to be done once but might take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching reference set.\n",
      "Finished fetching reference sequences for set: GRCh38.\n",
      "Finished fetching populations for species: homo_sapiens.\n",
      "Finished fetching individuals for population: African Caribbean in Barbados.\n",
      "Finished fetching individuals for population: African.\n",
      "Finished fetching individuals for population: All phase 3 individuals.\n",
      "Finished fetching individuals for population: American.\n",
      "Finished fetching individuals for population: African Ancestry in Southwest US.\n",
      "Finished fetching individuals for population: Bengali in Bangladesh.\n",
      "Finished fetching individuals for population: Chinese Dai in Xishuangbanna, China.\n",
      "Finished fetching individuals for population: Utah residents with Northern and Western European ancestry.\n",
      "Finished fetching individuals for population: Han Chinese in Bejing, China.\n",
      "Finished fetching individuals for population: Southern Han Chinese, China.\n",
      "Finished fetching individuals for population: Colombian in Medellin, Colombia.\n",
      "Finished fetching individuals for population: East Asian.\n",
      "Finished fetching individuals for population: Esan in Nigeria.\n",
      "Finished fetching individuals for population: European.\n",
      "Finished fetching individuals for population: Finnish in Finland.\n",
      "Finished fetching individuals for population: British in England and Scotland.\n",
      "Finished fetching individuals for population: Gujarati Indian in Houston, TX.\n",
      "Finished fetching individuals for population: Gambian in Western Division, The Gambia.\n",
      "Finished fetching individuals for population: Iberian populations in Spain.\n",
      "Finished fetching individuals for population: Indian Telugu in the UK.\n",
      "Finished fetching individuals for population: Japanese in Tokyo, Japan.\n",
      "Finished fetching individuals for population: Kinh in Ho Chi Minh City, Vietnam.\n",
      "Finished fetching individuals for population: Luhya in Webuye, Kenya.\n",
      "Finished fetching individuals for population: Mende in Sierra Leone.\n",
      "Finished fetching individuals for population: Mexican Ancestry in Los Angeles, California.\n",
      "Finished fetching individuals for population: Peruvian in Lima, Peru.\n",
      "Finished fetching individuals for population: Punjabi in Lahore, Pakistan.\n",
      "Finished fetching individuals for population: Puerto Rican in Puerto Rico.\n",
      "Finished fetching individuals for population: South Asian.\n",
      "Finished fetching individuals for population: Sri Lankan Tamil in the UK.\n",
      "Finished fetching individuals for population: Toscani in Italy.\n",
      "Finished fetching individuals for population: Yoruba in Ibadan, Nigeria.\n",
      "Finished fetching 10 variants next is 29941441.\n",
      "Finished fetching 10 variants next is 29941598.\n",
      "Finished fetching 10 variants next is 29941746.\n",
      "Finished fetching 10 variants next is 29941855.\n",
      "Finished fetching 10 variants next is 29942033.\n",
      "Finished fetching 10 variants next is 29942221.\n",
      "Finished fetching 10 variants next is 29942354.\n",
      "Finished fetching 10 variants next is 29942449.\n",
      "Finished fetching 10 variants next is 29942552.\n",
      "Finished fetching 10 variants next is 29942624.\n",
      "Finished fetching 10 variants next is 29942688.\n",
      "Finished fetching 10 variants next is 29942729.\n",
      "Finished fetching 10 variants next is 29942784.\n",
      "Finished fetching 10 variants next is 29942882.\n",
      "Finished fetching 10 variants next is 29942947.\n",
      "Finished fetching 10 variants next is 29942981.\n",
      "Finished fetching 10 variants next is 29943004.\n",
      "Finished fetching 10 variants next is 29943087.\n",
      "Finished fetching 10 variants next is 29943202.\n",
      "Finished fetching 10 variants next is 29943259.\n",
      "Finished fetching 10 variants next is 29943308.\n"
     ]
    }
   ],
   "source": [
    "if not fetched:\n",
    "    data_manager.fetch_all(29941260, 29945884, \"6\", report_progress = True)\n",
    "fetched = True\n",
    "%store fetched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following generates an inference matrix from the data provided by the local database. The inference matrix can be constructed with respect to a population and a section specified by start and end. Be sure to fetch the according population before constructing the matrix. If _sum_allels = True_ is passed, the expression for an individual per allele will be summed (if expressed on both -> 2, on one -> 1, on neither -> 0). Otherwise each strand will be represented by a seperate row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if inference_matrix is None:\n",
    "    inference_matrix, individual_map, variation_map = data_manager.generate_inference_matrix(start = 29941260, end = 29945884, population = \"ALL\")\n",
    "%store inference_matrix \n",
    "%store individual_map \n",
    "%store variation_map\n",
    "inference_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean number of variations per allele, for HLA-A as expected high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_matrix.sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train models with different initializations without seeding.\n",
    "\n",
    "Here we compute different models with varying dirichlet prior alpha. This prior is proportional to the probability of creating a new cluster, therefore inference with high alphas tends to begin with a higher number of clusters. This might take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if models is None:\n",
    "    models = [PiCollapsedNonparametricGibbsSampler(42), PiCollapsedNonparametricGibbsSampler(42), PiCollapsedNonparametricGibbsSampler(42)]\n",
    "    for i in range(0, len(models)):\n",
    "        print(\"Model {}:\".format(i))\n",
    "        models[i].fit(inference_matrix, num_burn_in_steps = 100, delta = 1, alpha = 10**(i - 1))\n",
    "for i in range(0, len(models)):\n",
    "    print(\"Model {}:\".format(i))\n",
    "    plt.clf()\n",
    "    plt.plot(models[i].ll_list)\n",
    "    plt.show()\n",
    "\n",
    "%store models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "May pre select models e.g. according to Aitikens Information Criterion (AIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AIC(model):\n",
    "    size = np.prod(np.shape(model.theta))\n",
    "    loglikelihood =model.ll_list[-1]\n",
    "    return 2*size - 2*loglikelihood\n",
    "\n",
    "print(list(map(lambda x: AIC(x), models)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2)\n",
    "principalComponents = pca.fit_transform(inference_matrix)\n",
    "pca.explained_variance_ratio_.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 50% of the variation can be explained by the first two principle components !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = list(individual_map.keys())\n",
    "inds.extend(list(individual_map.keys()))\n",
    "\n",
    "populations = [\"AFR\", \"AMR\", \"EAS\", \"EUR\", \"SAS\"]\n",
    "ind_map = data_manager.generate_individual_population_map()\n",
    "population_index = []\n",
    "for ind in inds:\n",
    "    for pop in ind_map[ind]:\n",
    "        if pop in populations:\n",
    "            population_index.append(populations.index(pop))\n",
    "pops = np.array(population_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population distribution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "\n",
    "for i in range(len(pops)):\n",
    "    ax.plot(principalComponents[pops == i,0], principalComponents[pops == i,1], \"o\", alpha=0.5)\n",
    "ax.legend(populations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "\n",
    "for i in range(int(max(models[0].Z))):\n",
    "    ax.plot(principalComponents[models[0].Z == i,0], principalComponents[models[0].Z == i,1], \"o\", alpha=0.5)\n",
    "ax.legend(range(int(max(models[0].Z))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict(zip([\"Cluster \" + str(i) for i in range(len(models[0].theta))], list(models[0].theta))))\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax = sns.heatmap(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following generates the distribution (as a dict) of amount of variations per strand in the specified region. I.e. {n : #strands with n variations}. And chooses one of the amounts according to the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = data_manager.get_variation_distribution(start = 17671934, end = 17681934, population = \"CHB\")\n",
    "choices = []\n",
    "probabilities = []\n",
    "for choice in distribution:\n",
    "    choices.append(choice)\n",
    "    probabilities.append(distribution[choice])\n",
    "choices = np.array(choices)\n",
    "probabilities = np.array(probabilities) / sum(probabilities)\n",
    "print(\"Choices: {}\".format(choices))\n",
    "print(\"Probabilities: {}\".format(probabilities))\n",
    "np.random.choice(choices, p=probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
